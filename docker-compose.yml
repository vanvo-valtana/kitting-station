version: '3.8'

services:
  app:
    # Our "Lab" container for JetPack 6.2.1
    # Ref: https://docs.nvidia.com/deeplearning/frameworks/install-pytorch-jetson-platform-release-notes/pytorch-jetson-rel.html
    image: nvcr.io/nvidia/pytorch:25.06-py3-igpu
    
    # Mount our project folder into the container
    volumes:
      - ./:/app
      
    # Pass through the STM32 Nucleo board - ON GOING
    
      
    # This is the key: gives the container GPU access
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
              
    # Keep the container alive for us to exec into
    # We will 'docker compose run' for main tasks
    command: tail -f /dev/null